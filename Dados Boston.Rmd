---
title: "Atividade Avaliatica 6"
author: "Edfram R Pereira"
date: "`r Sys.Date()`"
output:
  pdf_document:
      latex_engine: xelatex
header-includes:
  - \usepackage{amssymb}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Atividade -** Para compor a nota da disciplina o conjunto **Boston Housing Dataset** dispon√≠vel no R deve ser analisado. Informa√ß√µes sobre esses dados podem ser encontradas em: Boston function - RDocumentation.

Especificamente, deve-se predizer o *valor m√©dio das casas ocupadas pelo propriet√°rio (medv)* por meio das metodologias apresentadas na disciplina. Realize uma compara√ß√£o entre os modelos por meio de um processo de valida√ß√£o cruzada utilizando como medidas o erro quadr√°tico m√©dio e correla√ß√£o entre os valores preditos e observados. Fa√ßa um relat√≥rio. Tal relat√≥rio deve ser estregue de maneira organizada discutindo os resultados encontrados.

# Introdu√ß√£o

Para esta atividade usaremos o *R Studio* que trata-se de uma IDE (ambiente de desenvolvimento integrado) de c√≥digo aberto.

Vamos iniciar carregando os pacotes necess√°rios para fazer as an√°lises.

```{r}
library(tidyverse) # para realizar manipula√ß√£o de dados e visualiza√ß√£o

library(tree) # Carregar o pacote tree

library(randomForest) # Carregar o pacote randomForest

library(MASS) #Carregar o banco de dados

library(caret) # Trabalhar K-FOLD

library(rpart) # Trabalhar K-FOLD

library(rpart.plot)

library(ggplot2)

library(kableExtra)

```

Vamos carregar o pacote **MASS** que cont√©m o data frame *Boston*, que ser√° analisado neste trabalho, e o atribu√≠mos √† vari√°vel com o nome *dados*. Com a fun√ß√£o *head(dados)* visualizamos as 6 primeira linhas para termos uma visualiza√ß√£o pr√©via dos dados.

```{r}
dados <- Boston
head(dados)
```

Para uma melhor compreens√£o das vari√°veis dos dados utilizamos o recurso *?Boston* para ter acesso as descri√ß√µes dessas vari√°veis que est√£o na documenta√ß√£o do pacote *MASS vers√£o 7.3-61* apresentadas na tabela abaixo.

```{r}
?Boston
```

```{r nomedatabela}
df_tabela <- data.frame(Vari√°vel  = c("crim", "zn", "indus", "chas", 
"nox", "rm","age", "dis", "rad", "tax", "ptratio", "black", "lstat", "medv"), 
Descri√ß√£o = c("per capita crime rate by town.", 
"proportion of residential land zoned for lots over 25,000 sq.ft.",
"proportion of non-retail business acres per town.", 
"Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).",
"nitrogen oxides concentration (parts per 10 million).", 
"average number of rooms per dwelling.", 
"proportion of owner-occupied units built prior to 1940.", 
"weighted mean of distances to five Boston employment centres.", 
"index of accessibility to radial highways.", 
"full-value property-tax rate per $10,000.", 
"pupil-teacher ratio by town.", 
"1000(Bk‚àí0.63) 2  where ùêµùëòBk is the proportion of blacks by town.", 
"lower status of the population (percent).", 
"median value of owner-occupied homes in $1000s.")) 
df_tabela %>%
  kable(booktabs=T, caption="**Vari√°veis do dataset Boston**")
```

Ap√≥s compreender melhor as vari√°veis do banco de dados vamos particionar o conjunto de dados em dados de treinamento e dados de teste. Vamos realizar uma compara√ß√£o entre os modelos por meio de um processo de valida√ß√£o cruzada, com k=5, utilizando como medidas o erro quadr√°tico m√©dio e correla√ß√£o entre os valores preditos e observados.

```{r}
set.seed(12) # criamos uma semente

# Definir o n√∫mero de folds (k)
k <- 5

# Criar os folds
folds <- createFolds(dados$medv, k = k, list = TRUE, returnTrain = FALSE)

```

Estamos interessados em predizer o valor m√©dio das casas ocupadas pelo propriet√°rio (medv) em fun√ß√£o das outras 13 vari√°veis. Faremos isso utilizando os modelos **Regress√£o Linear**, **√Årvore de Regreess√£o**, **Bagging** e **Random Forest**.

# 1) Regress√£o Linear

## Valida√ß√£o Cruzada
Vamos ajustar nossa √°rvore com a fun√ß√£o *lm* onde a vari√°vel dependente *medv* ficar√° em fun√ß√£o das outras 13 vari√°veis. Utilizaremos o conjunto de dados *dados* e o subconjunto de treino *train*. Atribuimos o modelo √† vari√°vel **lm_model**.

```{r}
# Inicializar um vetor para armazenar as m√©tricas de desempenho
lm_rmse <- numeric(k)

# Realizar a valida√ß√£o cruzada k-fold
for (i in 1:k) {
  # Dividir os dados em conjunto de treinamento e teste
  lm_train_data <- dados[-folds[[i]], ]
  lm_test_data <- dados[folds[[i]], ]
  
  # Treinar o modelo linear m√∫ltiplo
  lm_model <- lm(medv ~ ., data = lm_train_data)
  
  # Fazer previs√µes no conjunto de teste
  lm_predictions <- predict(lm_model, newdata = lm_test_data)
  
  # Calcular o erro quadr√°tico m√©dio (RMSE)
  lm_rmse[i]  <- sqrt(mean(((lm_predictions - lm_test_data)$medv)^2))
}
```

Calculando a m√©dia do erro quadr√°tico m√©dio dos 5 valores calculados no processo de valida√ß√£o cruzada.

```{r}
# Calcular a m√©dia do RMSE
lm_mean_rmse <- mean(lm_rmse)

cat("Vetor dos RMSE = ", lm_rmse)

cat("\nM√©dia do RMSE do Regress√£o Linear:", lm_mean_rmse)
```

Calculando a correla√ß√£o entre os valores preditos e observados.

```{r}
##Capacidade preditiva (Correla√ß√£o)
lm_cp <- cor(lm_test_data$medv,lm_predictions)
lm_cp
```

Ap√≥s o modelo ser ajustado, solicitamos o resumo das informa√ß√µes do mesmo com a fun√ß√£o *summary*.

```{r}
summary(lm_model)
```


# 2) √Årvore de Regress√£o

## Valida√ß√£o Cruzada

Vamos ajustar nossa √°rvore com a fun√ß√£o *tree* onde a vari√°vel dependente *medv* ficar√° em fun√ß√£o das outras 13 vari√°veis. Utilizaremos o conjunto de dados *dados* e o subconjunto de treino *train*. Atribuimos o modelo √† vari√°vel **tree_model**.

```{r}
# Inicializar um vetor para armazenar as m√©tricas de desempenho
tree_rmse <- numeric(k)

# Realizar a valida√ß√£o cruzada k-fold
for (i in 1:k) {
  # Dividir os dados em conjunto de treinamento e teste
  tree_train_data <- dados[-folds[[i]], ]
  tree_test_data <- dados[folds[[i]], ]
  
  # Treinar o modelo arvore de regress√£o
  tree_model <- tree(medv ~ ., data = tree_train_data)
  
  # Prever as classes no conjunto de teste
  tree_predictions <- predict(tree_model, newdata = tree_test_data)
  
  # Calcular o erro quadr√°tico m√©dio (RMSE)
  tree_rmse[i] <- sqrt(mean((tree_predictions - tree_test_data$medv)^2))
}
```

Calculando a m√©dia do erro quadr√°tico m√©dio dos 5 valores calculados no processo de valida√ß√£o cruzada.

```{r}
# Calcular a m√©dia do RMSE
tree_mean_rmse <- mean(tree_rmse)

cat("Vetor dos RMSE = ", tree_rmse)

cat("\nM√©dia do RMSE:", tree_mean_rmse)
```

Calculando a correla√ß√£o entre os valores preditos e observados.

```{r}
##Capacidade preditiva (Correla√ß√£o)
tree_cp <- cor(tree_test_data$medv,tree_predictions)
tree_cp
```

Ap√≥s o modelo ser ajustado, solicitamos o resumo das informa√ß√µes do mesmo com a fun√ß√£o *summary*.

```{r}
summary(tree_model)
```

Notemos que apenas quatro vari√°veis foram utilizadas no ajuste do modelo, a saber, *lstat* (% menor status da popula√ß√£o), *rm* (n√∫mero m√©dio de quartos por habita√ß√£o),  *dis* (m√©dia ponderada das dist√¢ncias a cinco centros de emprego de Boston) e *nox* (concentra√ß√£o de √≥xidos de nitrog√™nio (partes por 10 milh√µes)).

Essa informa√ß√£o fica melhor visualizada no gr√°fico da √°rvore ajustada, abaixo.

```{r}
plot(tree_model, type = "uniform")
text(tree_model, cex = 0.95)
```

# 3) Bagging

## Valida√ß√£o Cruzada
Vamos ajustar nossa √°rvore com a fun√ß√£o *randomForest* onde a vari√°vel dependente *medv* ficar√° em fun√ß√£o das outras 13 vari√°veis. Utilizaremos o conjunto de dados *dados* e o subconjunto de treino *train*. Atribuimos o modelo √† vari√°vel **tree_model**.

```{r}
# Inicializar um vetor para armazenar as m√©tricas de desempenho
bag_rmse <- numeric(k)

# Realizar a valida√ß√£o cruzada k-fold
for (i in 1:k) {
  # Dividir os dados em conjunto de treinamento e teste
  bag_train_data <- dados[-folds[[i]], ]
  bag_test_data <- dados[folds[[i]], ]
  
  # Treinar o modelo linear m√∫ltiplo
  bag_model <- randomForest(medv ~ ., data = bag_train_data, mtry=13, importance =TRUE)
  
  # Prever as classes no conjunto de teste
  bag_predictions <- predict(bag_model, newdata = bag_test_data)
  
  # Calcular o erro quadr√°tico m√©dio (RMSE)
  bag_rmse[i] <- sqrt(mean((bag_predictions - bag_test_data$medv)^2))
}
```

Calculando a m√©dia do erro quadr√°tico m√©dio dos 5 valores calculados no processo de valida√ß√£o cruzada.

```{r}
# Calcular a m√©dia do RMSE
bag_mean_rmse <- mean(bag_rmse)

cat("Vetor dos RMSE = ", bag_rmse)

cat("\nM√©dia do RMSE:", bag_mean_rmse)
```

Calculando a correla√ß√£o entre os valores preditos e observados.

```{r}
##Capacidade preditiva (Correla√ß√£o)
bag_cp <- cor(bag_test_data$medv,bag_predictions)
bag_cp
```

Ap√≥s o modelo ser ajustado, plotamos o gr√°fico das vari√°veis importantes do modelo com a fun√ß√£o *varImpPlot*.

```{r}
varImpPlot(bag_model)
```

Notemos que apenas quatro vari√°veis s√£o mais importante no ajuste do modelo, a saber, *lstat* (% menor status da popula√ß√£o), *rm* (n√∫mero m√©dio de quartos por habita√ß√£o),  *dis* (m√©dia ponderada das dist√¢ncias a cinco centros de emprego de Boston) e *nox* (concentra√ß√£o de √≥xidos de nitrog√™nio (partes por 10 milh√µes)).

Essa informa√ß√£o fica melhor visualizada na tabela, abaixo.

```{r}
rf_imp <-importance(bag_model)
rf_imp
```


# 4) Random Forest

## valida√ß√£o cruzada

Vamos ajustar nossa √°rvore com a fun√ß√£o *randomForest* onde a vari√°vel dependente *medv* ficar√° em fun√ß√£o das outras 13 vari√°veis. Utilizaremos o conjunto de dados *dados* e o subconjunto de treino *train*. Atribuimos o modelo √† vari√°vel **rf_model**.


```{r}
# Inicializar um vetor para armazenar as m√©tricas de desempenho
rf_rmse <- numeric(k)

# Realizar a valida√ß√£o cruzada k-fold
for (i in 1:k) {
  # Dividir os dados em conjunto de treinamento e teste
  rf_train_data <- dados[-folds[[i]], ]
  rf_test_data <- dados[folds[[i]], ]
  
  # Treinar o modelo linear m√∫ltiplo
  rf_model <- randomForest(medv ~ ., data = rf_train_data, mtry=4, importance =TRUE)
  
  # Prever as classes no conjunto de teste
  rf_predictions <- predict(rf_model, newdata = rf_test_data)
  
  # Calcular o erro quadr√°tico m√©dio (RMSE)
  rf_rmse[i] <- sqrt(mean((rf_predictions - rf_test_data$medv)^2))
}
```

Calculando a m√©dia do erro quadr√°tico m√©dio dos 5 valores calculados no processo de valida√ß√£o cruzada.

```{r}
# Calcular a m√©dia do RMSE
rf_mean_rmse <- mean(rf_rmse)

cat("Vetor dos RMSE = ", rf_rmse)

cat("\nM√©dia do RMSE:", rf_mean_rmse)
```

Calculando a correla√ß√£o entre os valores preditos e observados.

```{r}
rf_cp <- cor(rf_test_data$medv,rf_predictions)
rf_cp
```

Ap√≥s o modelo ser ajustado, plotamos o gr√°fico das vari√°veis importantes do modelo com a fun√ß√£o *varImpPlot*.

```{r}
varImpPlot(rf_model)
```

Notemos que apenas duas vari√°veis s√£o mais desempenho papel importante no ajuste do modelo, a saber, *lstat* (% menor status da popula√ß√£o), *rm* (n√∫mero m√©dio de quartos por habita√ß√£o).

```{r}
rf_imp <-importance(rf_model)
rf_imp
```

# Conclus√£o

Abaixo plotamos os gr√°ficos de barras das m√©dia do erro quadr√°tico m√©dio dos 5 valores calculados no processo de valida√ß√£o cruzada e o das correla√ß√µes entre os valores preditos e observados dos quatro modelos usados.

## Gr√°fico de barra dos resultados

```{r}
resultados_RMSE <- data.frame(Modelos = c("Regress√£o Linear", "√Årvore de Regress√£o", 
                                          "Bagging", "Random Forest"),
 Resultado = c(lm_mean_rmse, tree_mean_rmse, bag_mean_rmse, rf_mean_rmse))
```

```{r}

ggplot(resultados_RMSE, aes(y = Resultado, x = Modelos, fill = tratamento)) +  
  geom_bar(stat = "identity", fill = gray(.3), width = .75)
```

```{r}
resultados_cp <- data.frame(Modelos = c("Regress√£o Linear", "√Årvore de Regress√£o", 
                                        "Bagging", "Random Forest"),
                 Resultado = c(lm_cp, tree_cp, bag_cp, rf_cp))
```

```{r}

ggplot(resultados_cp, aes(y = Resultado, x = Modelos, fill = tratamento)) +  
  geom_bar(stat = "identity", fill = gray(.3), width = .75)
```

Notamos que os modelos *Random Forest* e *Bagging* apresentaram as menores m√©dia do erro quadr√°tico m√©dio dos 5 valores calculados no processo de valida√ß√£o cruzada, a saber, 3.162411 e 3.262258, respectivamente. Esses dois modelos tamb√©m foram os que deram melhores resultados quando avaliamos as correla√ß√µes entre os valores preditos e observados.

Com isso esses resultados obtidos podemos escolher o Modelo *Random Forest* para fazer predi√ß√µes para o conjunto de dados estudados, pois o mesmo apresentou os melhores resultados.

